{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ee \n",
    "# from ee_plugin import Map \n",
    "import geemap\n",
    "import pprint as pprint\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import features collections and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=(40, -100), zoom=4)\n",
    "geometry = ee.FeatureCollection('users/2014ee070/YoloCountyBoundary')\n",
    "data = ee.FeatureCollection('users/2014ee070/yoloCDWR2016')\n",
    "yolo = geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2016-03-01'\n",
    "end_date = '2016-11-30'\n",
    "nClasses = 43\n",
    "num_classes = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Rice\", \"Alfalfa and Alfalfa Mixtures\", \"Wheat\", \"Sunflowers\", \"Safflower\", \"Corn, Sorghum and Sudan\",\n",
    "           \"Young Perennials\", \"Melons, Squash and Cucumbers\", \"Tomatoes\", \"Carrots\", \"Onions and Garlic\", \n",
    "           \"Potatoes and Sweet Potatoes\", \"Strawberries\", \"Bush Berries\", \"Cherries\", \"Beans (Dry)\", \"Peppers\",\n",
    "           \"Cole Crops\", \"Miscellaneous Truck Crops\", \"Miscellaneous Grain and Hay\", \"Miscellaneous Field Crops\", \n",
    "           \"Lettuce/Leafy Greens\", \"Olives\", \"Plums, Prunes and Apricots\", \"Pistachios\", \"Almonds\", \"Walnuts\", \"Grapes\", \n",
    "           \"Pears\", \"Apples\", \"Citrus\", \"Miscellaneous Subtropical Fruits\", \"Peaches/Nectarines\", \"Pomegranates\", \n",
    "           \"Dates\", \"Flowers, Nursery and Christmas Tree Farms\", \"Miscellaneous Grasses\", \"Miscellaneous Deciduous\", \n",
    "           \"Mixed Pasture\", \"Greenhouse\", \"Managed Wetland\", \"Idle\", \"Urban\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskL8sr(image):\n",
    "    # Bit 4: Cloud\n",
    "    # Bit 5,6: Cloud confidence\n",
    "    # Bit 7,8: Cloud Shadow\n",
    "    cloudShadowBitMask = 1 << 8\n",
    "    cloudConfidenceBitMask = 1 << 6\n",
    "    cloudsBitMask = 1 << 4\n",
    "\n",
    "    # Get the pixel QA band.\n",
    "    qa = image.select('BQA')\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0) \\\n",
    "      .And(qa.bitwiseAnd(cloudConfidenceBitMask).eq(0)) \\\n",
    "      .And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "\n",
    "    # Return the masked image, scaled to reflectance, without the QA bands.\n",
    "    return image.updateMask(mask) \\\n",
    "      .select(\"B[2-7]*\").divide(10000) \\\n",
    "      .copyProperties(image, [\"system:time_start\"])\n",
    "\n",
    "\n",
    "def addNDVI(image):\n",
    "    ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "\n",
    "def addGNDVI(image):\n",
    "    gndvi = image.normalizedDifference(['B5', 'B3']).rename('GNDVI')\n",
    "    return image.addBands(gndvi)\n",
    "\n",
    "\n",
    "def addEVI(image):\n",
    "    evi = image.expression(\"2.5 * ((nir-red)/(nir + 6*red -7.5*blue + 1))\",\n",
    "    {\n",
    "    'nir' : image.select(\"B5\"),\n",
    "    'red' : image.select(\"B4\"),\n",
    "    'blue': image.select(\"B2\")\n",
    "    }).rename('EVI')\n",
    "    return image.addBands(evi)\n",
    "\n",
    "\n",
    "def addSAVI(image):\n",
    "    savi = image.expression(\"1.5*(red-green)/(red+green+0.5)\",\n",
    "    {\n",
    "    'red' : image.select(\"B4\"),\n",
    "    'green': image.select(\"B3\")\n",
    "    }).rename('SAVI')\n",
    "    return image.addBands(savi)\n",
    "\n",
    "\n",
    "def addNDWI(image):\n",
    "    ndwi = image.normalizedDifference(['B3', 'B5']).rename('NDWI')\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "def addNDBI(image):\n",
    "    ndbi = image.normalizedDifference(['B6', 'B5']).rename('NDBI')\n",
    "    return image.addBands(ndbi)\n",
    "\n",
    "def addBSI(image):\n",
    "    bsi = image.expression(\"((swir + red) - (nir + blue))/((swir + red) + (nir + blue))\",\n",
    "    {\n",
    "    'blue' : image.select(\"B2\"),\n",
    "    'red' : image.select(\"B4\"),\n",
    "    'nir' : image.select(\"B5\"),\n",
    "    'swir': image.select(\"B6\")\n",
    "    }).rename('BSI')\n",
    "    bsi = bsi.divide(10000)\n",
    "    return image.addBands(bsi) \n",
    "\n",
    "def ymdList(imgcol):\n",
    "    def iter_func(image, newlist):\n",
    "        date = ee.String(image.date().format(\"YYYY-MM-dd\"))\n",
    "        newlist = ee.List(newlist)\n",
    "        return ee.List(newlist.add(date).sort())\n",
    "\n",
    "    return imgcol.iterate(iter_func, ee.List([]))\n",
    "\n",
    "def temporalCollection(collection, start, count, interval, units):\n",
    "    sequence = ee.List.sequence(0, ee.Number(count).subtract(1))\n",
    "    originalStartDate = ee.Date(start)\n",
    "\n",
    "    def func_aoa(i):\n",
    "        startDate = originalStartDate.advance(ee.Number(interval).multiply(i), units)\n",
    "        endDate = originalStartDate.advance(ee.Number(interval).multiply(ee.Number(i).add(1)), units)\n",
    "        resultImage = collection.filterDate(startDate, endDate).median() \\\n",
    "                          .set('system:time_start', startDate.millis()) \\\n",
    "                          .set('system:time_end', endDate.millis())\n",
    "        return resultImage\n",
    "\n",
    "    return ee.ImageCollection(sequence.map(func_aoa))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Imagery Landsat 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images In collection 19\n"
     ]
    }
   ],
   "source": [
    "Map.centerObject(geometry)\n",
    "l8Collection = ee.ImageCollection(\"LANDSAT/LC08/C01/T1\") \\\n",
    "                  .filterDate(start_date, end_date) \\\n",
    "                  .filterBounds(geometry) \\\n",
    "                  .filter(ee.Filter.lt('CLOUD_COVER', 10)) \\\n",
    "                  .map(maskL8sr) \\\n",
    "                  .map(addNDVI).map(addGNDVI).map(addEVI).map(addSAVI).map(addBSI).map(addNDWI).map(addNDBI) \\\n",
    "                  .sort('system:time_start', True)\n",
    "# ['B2', 'B3', 'B4', 'B5', 'B6','B7', 'NDVI', 'GNDVI', 'EVI', 'SAVI', 'BSI', 'NDWI', 'NDBI']\n",
    "print(\"images In collection\",l8Collection.size().getInfo())\n",
    "l8Collection = temporalCollection(l8Collection, start_date, 9, 30, 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying all images selected each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-01 00:00:00\n",
      "2016-03-31 00:00:00\n",
      "2016-04-30 00:00:00\n",
      "2016-05-30 00:00:00\n",
      "2016-06-29 00:00:00\n",
      "2016-07-29 00:00:00\n",
      "2016-08-28 00:00:00\n",
      "2016-09-27 00:00:00\n",
      "2016-10-27 00:00:00\n",
      "All features ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'NDVI', 'GNDVI', 'EVI', 'SAVI', 'BSI', 'NDWI', 'NDBI', 'B2_1', 'B3_1', 'B4_1', 'B5_1', 'B6_1', 'B7_1', 'NDVI_1', 'GNDVI_1', 'EVI_1', 'SAVI_1', 'BSI_1', 'NDWI_1', 'NDBI_1', 'B2_2', 'B3_2', 'B4_2', 'B5_2', 'B6_2', 'B7_2', 'NDVI_2', 'GNDVI_2', 'EVI_2', 'SAVI_2', 'BSI_2', 'NDWI_2', 'NDBI_2', 'B2_3', 'B3_3', 'B4_3', 'B5_3', 'B6_3', 'B7_3', 'NDVI_3', 'GNDVI_3', 'EVI_3', 'SAVI_3', 'BSI_3', 'NDWI_3', 'NDBI_3', 'B2_4', 'B3_4', 'B4_4', 'B5_4', 'B6_4', 'B7_4', 'NDVI_4', 'GNDVI_4', 'EVI_4', 'SAVI_4', 'BSI_4', 'NDWI_4', 'NDBI_4', 'B2_5', 'B3_5', 'B4_5', 'B5_5', 'B6_5', 'B7_5', 'NDVI_5', 'GNDVI_5', 'EVI_5', 'SAVI_5', 'BSI_5', 'NDWI_5', 'NDBI_5', 'B2_6', 'B3_6', 'B4_6', 'B5_6', 'B6_6', 'B7_6', 'NDVI_6', 'GNDVI_6', 'EVI_6', 'SAVI_6', 'BSI_6', 'NDWI_6', 'NDBI_6', 'B2_7', 'B3_7', 'B4_7', 'B5_7', 'B6_7', 'B7_7', 'NDVI_7', 'GNDVI_7', 'EVI_7', 'SAVI_7', 'BSI_7', 'NDWI_7', 'NDBI_7', 'B2_8', 'B3_8', 'B4_8', 'B5_8', 'B6_8', 'B7_8', 'NDVI_8', 'GNDVI_8', 'EVI_8', 'SAVI_8', 'BSI_8', 'NDWI_8', 'NDBI_8']\n"
     ]
    }
   ],
   "source": [
    "# # #*************** Get 12 images from L8 ***********************#\n",
    "\n",
    "l8ImagesList = l8Collection.toList(l8Collection.size())\n",
    "finalImage = ee.Image(l8ImagesList.get(0)).clip(geometry)\n",
    "ts = ee.Image(l8ImagesList.get(0)).get('system:time_start').getInfo()\n",
    "print(datetime.utcfromtimestamp(ts/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Map.addLayer(finalImage, {'bands': ['B4', 'B3', 'B2'], 'min':6000,'max': 12000}, 'L8-1')\n",
    "\n",
    "n = 1\n",
    "i = 1\n",
    "while i < 9:\n",
    "    n = n + 1\n",
    "    current = ee.Image(l8ImagesList.get(i)).clip(geometry)\n",
    "\n",
    "    if(i == 1):\n",
    "        currentDate = ee.Date(current.get('system:time_start'))\n",
    "        meanImage = l8Collection.filterDate(\n",
    "                    currentDate.advance(-1, 'month'), currentDate.advance(1, 'month')).mean() \\\n",
    "                    .clip(yolo) \\\n",
    "                    .set('system:time_start', currentDate.millis())\n",
    "        current = meanImage.where(current, current)\n",
    "\n",
    "    ts = current.get('system:time_start').getInfo()\n",
    "    print(datetime.utcfromtimestamp(ts/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    finalImage = finalImage.addBands(current)\n",
    "    # Map.addLayer(current, {'bands': ['B4', 'B3', 'B2'], 'min':6000,'max': 12000}, 'L8-'+n)\n",
    "    i = i + 1\n",
    "\n",
    "image = finalImage.clip(geometry).toFloat()\n",
    "featuresNames = image.bandNames()\n",
    "print('All features', featuresNames.getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIltering and remapping CRS data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rice',\n",
      " 'Alfalfa and Alfalfa Mixtures',\n",
      " 'Wheat',\n",
      " 'Sunflowers',\n",
      " 'Safflower',\n",
      " 'Corn, Sorghum and Sudan',\n",
      " 'Young Perennials',\n",
      " 'Melons, Squash and Cucumbers',\n",
      " 'Tomatoes',\n",
      " 'Carrots',\n",
      " 'Onions and Garlic',\n",
      " 'Potatoes and Sweet Potatoes',\n",
      " 'Strawberries',\n",
      " 'Bush Berries',\n",
      " 'Cherries',\n",
      " 'Beans (Dry)',\n",
      " 'Peppers',\n",
      " 'Cole Crops',\n",
      " 'Miscellaneous Truck Crops',\n",
      " 'Miscellaneous Grain and Hay',\n",
      " 'Miscellaneous Field Crops',\n",
      " 'Lettuce/Leafy Greens',\n",
      " 'Olives',\n",
      " 'Plums, Prunes and Apricots',\n",
      " 'Pistachios',\n",
      " 'Almonds',\n",
      " 'Walnuts',\n",
      " 'Grapes',\n",
      " 'Pears',\n",
      " 'Apples',\n",
      " 'Citrus',\n",
      " 'Miscellaneous Subtropical Fruits',\n",
      " 'Peaches/Nectarines',\n",
      " 'Pomegranates',\n",
      " 'Dates',\n",
      " 'Flowers, Nursery and Christmas Tree Farms',\n",
      " 'Miscellaneous Grasses',\n",
      " 'Miscellaneous Deciduous',\n",
      " 'Mixed Pasture',\n",
      " 'Greenhouse',\n",
      " 'Managed Wetland',\n",
      " 'Idle',\n",
      " 'Urban']\n",
      "{'Alfalfa and Alfalfa Mixtures': 575,\n",
      " 'Almonds': 753,\n",
      " 'Apples': 13,\n",
      " 'Beans (Dry)': 26,\n",
      " 'Bush Berries': 4,\n",
      " 'Carrots': 9,\n",
      " 'Cherries': 5,\n",
      " 'Citrus': 32,\n",
      " 'Cole Crops': 5,\n",
      " 'Corn, Sorghum and Sudan': 150,\n",
      " 'Dates': 2,\n",
      " 'Flowers, Nursery and Christmas Tree Farms': 22,\n",
      " 'Grapes': 688,\n",
      " 'Greenhouse': 7,\n",
      " 'Idle': 695,\n",
      " 'Lettuce/Leafy Greens': 2,\n",
      " 'Managed Wetland': 25,\n",
      " 'Melons, Squash and Cucumbers': 168,\n",
      " 'Miscellaneous Deciduous': 82,\n",
      " 'Miscellaneous Field Crops': 2,\n",
      " 'Miscellaneous Grain and Hay': 441,\n",
      " 'Miscellaneous Grasses': 53,\n",
      " 'Miscellaneous Subtropical Fruits': 1,\n",
      " 'Miscellaneous Truck Crops': 184,\n",
      " 'Mixed Pasture': 387,\n",
      " 'Olives': 141,\n",
      " 'Onions and Garlic': 34,\n",
      " 'Peaches/Nectarines': 13,\n",
      " 'Pears': 17,\n",
      " 'Peppers': 14,\n",
      " 'Pistachios': 46,\n",
      " 'Plums, Prunes and Apricots': 64,\n",
      " 'Pomegranates': 3,\n",
      " 'Potatoes and Sweet Potatoes': 6,\n",
      " 'Rice': 350,\n",
      " 'Safflower': 161,\n",
      " 'Strawberries': 2,\n",
      " 'Sunflowers': 379,\n",
      " 'Tomatoes': 596,\n",
      " 'Urban': 12,\n",
      " 'Walnuts': 494,\n",
      " 'Wheat': 471,\n",
      " 'Young Perennials': 230}\n"
     ]
    }
   ],
   "source": [
    "#************* remapping crops to major crops *****************#\n",
    "\n",
    "classSizes = {}\n",
    "for i in range(0, nClasses, 1):\n",
    "    classSizes[classes[i]] = data.filter(ee.Filter.eq('landcover', i)).size().getInfo()\n",
    "\n",
    "pprint.pprint(classes)\n",
    "pprint.pprint(classSizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data and making image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4408 1467 1489\n"
     ]
    }
   ],
   "source": [
    "yolo_data = data.randomColumn('random', 2016)\n",
    "training = yolo_data.filter(ee.Filter.lt('random', 0.6));\n",
    "validation = yolo_data.filter(ee.Filter.And(\n",
    "                      ee.Filter.gte('random', 0.6), \n",
    "                      ee.Filter.lt('random', 0.8)));\n",
    "testing = yolo_data.filter(ee.Filter.gte('random', 0.8));\n",
    "print(training.size().getInfo(), validation.size().getInfo(), testing.size().getInfo())\n",
    "\n",
    "training_label = training.reduceToImage(\n",
    "    properties =  ['landcover'],\n",
    "    reducer = ee.Reducer.first()\n",
    ")\n",
    "val_label = validation.reduceToImage(\n",
    "    properties =  ['landcover'],\n",
    "    reducer = ee.Reducer.first()\n",
    ")\n",
    "testing_label = testing.reduceToImage(\n",
    "    properties =  ['landcover'],\n",
    "    reducer = ee.Reducer.first()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432\n"
     ]
    }
   ],
   "source": [
    "a = validation.filter(ee.Filter.eq('MULTIUSE', 'S'))\n",
    "print(a.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n"
     ]
    }
   ],
   "source": [
    "a = testing.filter(ee.Filter.eq('MULTIUSE', 'S'))\n",
    "print(a.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff4289a30fc4f239dca4af7c61e35f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38.66289070025362, -121.81103976701577], controls=(WidgetControl(options=['position'], widget=HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(training_label, {'palette': 'FF0000'}, 'Training')\n",
    "Map.addLayer(val_label, {'palette': '0000FF'}, 'validation')\n",
    "Map.addLayer(testing_label, {'palette': '0000FF'}, 'Testing')\n",
    "Map.centerObject(training, 10)\n",
    "Map.addLayer(patch2)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_labels = [0, 1, 2, 3, 4, 5, 6, 8, 19, 27, \n",
    "#               14, 23, 24, 25, 26, 28, 29, 32, 33, 37, \n",
    "#               22, 30, 31, 34,\n",
    "#               36, 38, \n",
    "#               7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 35, 39, \n",
    "#               40, 41, 42]\n",
    "# new_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \n",
    "#               10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
    "#               11, 11, 11, 11, \n",
    "#               12, 12, \n",
    "#               13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, \n",
    "#               14, 15, 16]\n",
    "# training = training.remap(\n",
    "#   lookupIn = old_labels,\n",
    "#   lookupOut = new_labels,\n",
    "#   columnName = 'landcover',\n",
    "# )\n",
    "\n",
    "# validation = validation.remap(\n",
    "#   lookupIn = old_labels,\n",
    "#   lookupOut = new_labels,\n",
    "#   columnName = 'landcover',\n",
    "# )\n",
    "\n",
    "# testing = testing.remap(\n",
    "#   lookupIn = old_labels,\n",
    "#   lookupOut = new_labels,\n",
    "#   columnName = 'landcover',\n",
    "# )\n",
    "# #************* converting shapefile vector to raster ****************#\n",
    "\n",
    "\n",
    "# # label = label.remap(old_labels,\n",
    "# #   to = new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = yolo_data.reduceToImage(\n",
    "    properties =  ['landcover'],\n",
    "    reducer = ee.Reducer.first()\n",
    ")\n",
    "label = label.select('first').rename('landcover')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making final Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "image = finalImage.addBands(label).toFloat()\n",
    "\n",
    "neighbourhood_image = image.neighborhoodToArray(ee.Kernel.rectangle(kernel_size, kernel_size, 'pixels'))\n",
    "# Map.addLayer(neighbourhood_image, {'bands': ['B4', 'B3', 'B2'], 'min': 6000, 'max': 12000}, 'L8_extended')\n",
    "Map.addLayer(neighbourhood_image, {'bands': ['B4', 'B3', 'B2'], 'min': 0.6, 'max': 1.2}, 'L8_extended')\n",
    "\n",
    "Map.centerObject(yolo)\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B2',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B5',\n",
       " 'B6',\n",
       " 'B7',\n",
       " 'NDWI',\n",
       " 'NDBI',\n",
       " 'NDVI',\n",
       " 'GNDVI',\n",
       " 'EVI',\n",
       " 'SAVI',\n",
       " 'BSI',\n",
       " 'B2_1',\n",
       " 'B3_1',\n",
       " 'B4_1',\n",
       " 'B5_1',\n",
       " 'B6_1',\n",
       " 'B7_1',\n",
       " 'NDWI_1',\n",
       " 'NDBI_1',\n",
       " 'NDVI_1',\n",
       " 'GNDVI_1',\n",
       " 'EVI_1',\n",
       " 'SAVI_1',\n",
       " 'BSI_1',\n",
       " 'B2_2',\n",
       " 'B3_2',\n",
       " 'B4_2',\n",
       " 'B5_2',\n",
       " 'B6_2',\n",
       " 'B7_2',\n",
       " 'NDWI_2',\n",
       " 'NDBI_2',\n",
       " 'NDVI_2',\n",
       " 'GNDVI_2',\n",
       " 'EVI_2',\n",
       " 'SAVI_2',\n",
       " 'BSI_2',\n",
       " 'B2_3',\n",
       " 'B3_3',\n",
       " 'B4_3',\n",
       " 'B5_3',\n",
       " 'B6_3',\n",
       " 'B7_3',\n",
       " 'NDWI_3',\n",
       " 'NDBI_3',\n",
       " 'NDVI_3',\n",
       " 'GNDVI_3',\n",
       " 'EVI_3',\n",
       " 'SAVI_3',\n",
       " 'BSI_3',\n",
       " 'B2_4',\n",
       " 'B3_4',\n",
       " 'B4_4',\n",
       " 'B5_4',\n",
       " 'B6_4',\n",
       " 'B7_4',\n",
       " 'NDWI_4',\n",
       " 'NDBI_4',\n",
       " 'NDVI_4',\n",
       " 'GNDVI_4',\n",
       " 'EVI_4',\n",
       " 'SAVI_4',\n",
       " 'BSI_4',\n",
       " 'B2_5',\n",
       " 'B3_5',\n",
       " 'B4_5',\n",
       " 'B5_5',\n",
       " 'B6_5',\n",
       " 'B7_5',\n",
       " 'NDWI_5',\n",
       " 'NDBI_5',\n",
       " 'NDVI_5',\n",
       " 'GNDVI_5',\n",
       " 'EVI_5',\n",
       " 'SAVI_5',\n",
       " 'BSI_5',\n",
       " 'B2_6',\n",
       " 'B3_6',\n",
       " 'B4_6',\n",
       " 'B5_6',\n",
       " 'B6_6',\n",
       " 'B7_6',\n",
       " 'NDWI_6',\n",
       " 'NDBI_6',\n",
       " 'NDVI_6',\n",
       " 'GNDVI_6',\n",
       " 'EVI_6',\n",
       " 'SAVI_6',\n",
       " 'BSI_6',\n",
       " 'B2_7',\n",
       " 'B3_7',\n",
       " 'B4_7',\n",
       " 'B5_7',\n",
       " 'B6_7',\n",
       " 'B7_7',\n",
       " 'NDWI_7',\n",
       " 'NDBI_7',\n",
       " 'NDVI_7',\n",
       " 'GNDVI_7',\n",
       " 'EVI_7',\n",
       " 'SAVI_7',\n",
       " 'BSI_7',\n",
       " 'B2_8',\n",
       " 'B3_8',\n",
       " 'B4_8',\n",
       " 'B5_8',\n",
       " 'B6_8',\n",
       " 'B7_8',\n",
       " 'NDWI_8',\n",
       " 'NDBI_8',\n",
       " 'NDVI_8',\n",
       " 'GNDVI_8',\n",
       " 'EVI_8',\n",
       " 'SAVI_8',\n",
       " 'BSI_8',\n",
       " 'landcover']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbourhood_image.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B2',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B5',\n",
       " 'B6',\n",
       " 'B7',\n",
       " 'NDWI',\n",
       " 'NDBI',\n",
       " 'NDVI',\n",
       " 'GNDVI',\n",
       " 'EVI',\n",
       " 'SAVI',\n",
       " 'BSI',\n",
       " 'B2_1',\n",
       " 'B3_1',\n",
       " 'B4_1',\n",
       " 'B5_1',\n",
       " 'B6_1',\n",
       " 'B7_1',\n",
       " 'NDWI_1',\n",
       " 'NDBI_1',\n",
       " 'NDVI_1',\n",
       " 'GNDVI_1',\n",
       " 'EVI_1',\n",
       " 'SAVI_1',\n",
       " 'BSI_1',\n",
       " 'B2_2',\n",
       " 'B3_2',\n",
       " 'B4_2',\n",
       " 'B5_2',\n",
       " 'B6_2',\n",
       " 'B7_2',\n",
       " 'NDWI_2',\n",
       " 'NDBI_2',\n",
       " 'NDVI_2',\n",
       " 'GNDVI_2',\n",
       " 'EVI_2',\n",
       " 'SAVI_2',\n",
       " 'BSI_2',\n",
       " 'B2_3',\n",
       " 'B3_3',\n",
       " 'B4_3',\n",
       " 'B5_3',\n",
       " 'B6_3',\n",
       " 'B7_3',\n",
       " 'NDWI_3',\n",
       " 'NDBI_3',\n",
       " 'NDVI_3',\n",
       " 'GNDVI_3',\n",
       " 'EVI_3',\n",
       " 'SAVI_3',\n",
       " 'BSI_3',\n",
       " 'B2_4',\n",
       " 'B3_4',\n",
       " 'B4_4',\n",
       " 'B5_4',\n",
       " 'B6_4',\n",
       " 'B7_4',\n",
       " 'NDWI_4',\n",
       " 'NDBI_4',\n",
       " 'NDVI_4',\n",
       " 'GNDVI_4',\n",
       " 'EVI_4',\n",
       " 'SAVI_4',\n",
       " 'BSI_4',\n",
       " 'B2_5',\n",
       " 'B3_5',\n",
       " 'B4_5',\n",
       " 'B5_5',\n",
       " 'B6_5',\n",
       " 'B7_5',\n",
       " 'NDWI_5',\n",
       " 'NDBI_5',\n",
       " 'NDVI_5',\n",
       " 'GNDVI_5',\n",
       " 'EVI_5',\n",
       " 'SAVI_5',\n",
       " 'BSI_5',\n",
       " 'B2_6',\n",
       " 'B3_6',\n",
       " 'B4_6',\n",
       " 'B5_6',\n",
       " 'B6_6',\n",
       " 'B7_6',\n",
       " 'NDWI_6',\n",
       " 'NDBI_6',\n",
       " 'NDVI_6',\n",
       " 'GNDVI_6',\n",
       " 'EVI_6',\n",
       " 'SAVI_6',\n",
       " 'BSI_6',\n",
       " 'B2_7',\n",
       " 'B3_7',\n",
       " 'B4_7',\n",
       " 'B5_7',\n",
       " 'B6_7',\n",
       " 'B7_7',\n",
       " 'NDWI_7',\n",
       " 'NDBI_7',\n",
       " 'NDVI_7',\n",
       " 'GNDVI_7',\n",
       " 'EVI_7',\n",
       " 'SAVI_7',\n",
       " 'BSI_7',\n",
       " 'B2_8',\n",
       " 'B3_8',\n",
       " 'B4_8',\n",
       " 'B5_8',\n",
       " 'B6_8',\n",
       " 'B7_8',\n",
       " 'NDWI_8',\n",
       " 'NDBI_8',\n",
       " 'NDVI_8',\n",
       " 'GNDVI_8',\n",
       " 'EVI_8',\n",
       " 'SAVI_8',\n",
       " 'BSI_8',\n",
       " 'landcover']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampling only points for now\n",
    "training_points = image.select('landcover')\\\n",
    "          .sampleRegions(\n",
    "            collection= training,\n",
    "            scale=80,\n",
    "            tileScale =1,\n",
    "            properties= ['landcover'],\n",
    "            geometries = True\n",
    "          )\n",
    "val_points = image.select('landcover')\\\n",
    "          .sampleRegions(\n",
    "            collection= validation,\n",
    "            scale=80,\n",
    "            tileScale = 1,\n",
    "            properties= ['landcover'],\n",
    "            geometries = True\n",
    "          )\n",
    "\n",
    "testing_points = image.select('landcover')\\\n",
    "          .sampleRegions(\n",
    "            collection= testing,\n",
    "            scale=80,\n",
    "            tileScale = 1,\n",
    "            properties= ['landcover'],\n",
    "            geometries = True\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get lat longs of sampled points\n",
    "# training_pts = training_points.geometry().getInfo()['coordinates']\n",
    "# val_pts = val_points.geometry().getInfo()['coordinates']\n",
    "# testing_pts = testing_points.geometry().getInfo()['coordinates']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156470, 59728, 69150)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_pts), len(val_pts), len(testing_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch2 = ee.Geometry.Polygon([[-121.98298540330632,38.589919143886206],\n",
    "[-121.77287187791569,38.589919143886206],\n",
    "[-121.77287187791569,38.68110064858854],\n",
    "[-121.98298540330632,38.68110064858854],\n",
    "[-121.98298540330632,38.589919143886206]])\n",
    "Map.addLayer(patch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch2 = yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task = ee.batch.Export.image.toDrive(\n",
    "    image = image.clip(patch2),\n",
    "    description = 'patch of yolo',\n",
    "    folder = 'Yolo_2016_patch',\n",
    "    fileNamePrefix = 'Yolo_2016_patch5',\n",
    "    scale = 30,\n",
    "    fileFormat = 'GeoTIFF',\n",
    "    region = patch2\n",
    ")\n",
    "Task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.150368959482066"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch2.area(0.01).divide(1e6).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_features = testing.toList(1489)\n",
    "# for i in range(1489):\n",
    "#     feature = ee.Feature(testing_features.get(i))\n",
    "#     fcp = testing_points.filterBounds(feature.geometry())\n",
    "#     train_db = neighbourhood_image.sampleRegions(collection=fcp, scale=30)\n",
    "#     Task = ee.batch.Export.table.toDrive(\n",
    "#         collection=train_db,        \n",
    "#         description=\"testing_yolo_2016\"+str(i),\n",
    "#         fileNamePrefix=\"testing_yolo_2016_\"+str(i),\n",
    "#         folder = \"testing_polygons_yolo_2016_30\",  \n",
    "#         fileFormat='TFRecord')\n",
    "#     Task.start()\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_features = validation.toList(1467)\n",
    "# for i in range(1467):\n",
    "#     feature = ee.Feature(val_features.get(i))\n",
    "#     fcp = val_points.filterBounds(feature.geometry())\n",
    "#     train_db = neighbourhood_image.sampleRegions(collection=fcp, scale=30)\n",
    "#     Task = ee.batch.Export.table.toDrive(\n",
    "#         collection=train_db,        \n",
    "#         description=\"validation_yolo_2016\"+str(i),\n",
    "#         fileNamePrefix=\"validation_yolo_2016_\"+str(i),\n",
    "#         folder = \"validation_polygons_yolo_2016_30\",  \n",
    "#         fileFormat='TFRecord')\n",
    "#     Task.start()\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_2D_samples(collection, num_of_images, num_features, dimension, file_name_prefix, folder_name):\n",
    "    filenames = []\n",
    "    nbands = num_of_images*num_features+1\n",
    "    nfeatures = dimension*dimension*nbands*len(collection) #estimate the totals # of features\n",
    "\n",
    "    nparts = int(np.ceil(nfeatures/3e6))\n",
    "    print('Dataset too long, splitting it into '+ str(nparts),'equal parts.')\n",
    "\n",
    "\n",
    "    nppoints = np.array(collection)\n",
    "    np.random.shuffle(nppoints)\n",
    "\n",
    "    count_batch = 1  # Batch counter \n",
    "\n",
    "    for batch_arr in np.array_split(nppoints,nparts):\n",
    "\n",
    "        fcp = ee.FeatureCollection([ee.Feature(ee.Geometry.Point(p),{'class':'NA'}) for p in batch_arr.tolist()])\n",
    "\n",
    "        train_db = neighbourhood_image.sampleRegions(collection=fcp, scale=30)\n",
    "\n",
    "        filename = file_name_prefix + str(count_batch)\n",
    "        print('sending the task #%04d'%count_batch)\n",
    "        Task = ee.batch.Export.table.toDrive(\n",
    "                collection=train_db,        \n",
    "                description=file_name_prefix+str(count_batch),\n",
    "                fileNamePrefix=filename,\n",
    "                folder = folder_name,  \n",
    "                fileFormat='TFRecord')\n",
    "\n",
    "        Task.start()\n",
    "        filenames.append(filename)\n",
    "        count_batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset too long, splitting it into 44 equal parts.\n",
      "sending the task #0001\n",
      "sending the task #0002\n",
      "sending the task #0003\n",
      "sending the task #0004\n",
      "sending the task #0005\n",
      "sending the task #0006\n",
      "sending the task #0007\n",
      "sending the task #0008\n",
      "sending the task #0009\n",
      "sending the task #0010\n",
      "sending the task #0011\n",
      "sending the task #0012\n",
      "sending the task #0013\n",
      "sending the task #0014\n",
      "sending the task #0015\n",
      "sending the task #0016\n",
      "sending the task #0017\n",
      "sending the task #0018\n",
      "sending the task #0019\n",
      "sending the task #0020\n",
      "sending the task #0021\n",
      "sending the task #0022\n",
      "sending the task #0023\n",
      "sending the task #0024\n",
      "sending the task #0025\n",
      "sending the task #0026\n",
      "sending the task #0027\n",
      "sending the task #0028\n",
      "sending the task #0029\n",
      "sending the task #0030\n",
      "sending the task #0031\n",
      "sending the task #0032\n",
      "sending the task #0033\n",
      "sending the task #0034\n",
      "sending the task #0035\n",
      "sending the task #0036\n",
      "sending the task #0037\n",
      "sending the task #0038\n",
      "sending the task #0039\n",
      "sending the task #0040\n",
      "sending the task #0041\n",
      "sending the task #0042\n",
      "sending the task #0043\n",
      "sending the task #0044\n"
     ]
    }
   ],
   "source": [
    "export_2D_samples(collection = training_pts, \n",
    "                  num_of_images = 9, \n",
    "                  num_features = 13, \n",
    "                  dimension = 7, \n",
    "                  file_name_prefix = \"training_yolo_2016_\", \n",
    "                  folder_name = \"training_yolo_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset too long, splitting it into 17 equal parts.\n",
      "sending the task #0001\n",
      "sending the task #0002\n",
      "sending the task #0003\n",
      "sending the task #0004\n",
      "sending the task #0005\n",
      "sending the task #0006\n",
      "sending the task #0007\n",
      "sending the task #0008\n",
      "sending the task #0009\n",
      "sending the task #0010\n",
      "sending the task #0011\n",
      "sending the task #0012\n",
      "sending the task #0013\n",
      "sending the task #0014\n",
      "sending the task #0015\n",
      "sending the task #0016\n",
      "sending the task #0017\n"
     ]
    }
   ],
   "source": [
    "export_2D_samples(collection = val_pts, \n",
    "                  num_of_images = 9, \n",
    "                  num_features = 13, \n",
    "                  dimension = 7, \n",
    "                  file_name_prefix = \"validation_yolo_2016_\", \n",
    "                  folder_name = \"validation_yolo_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset too long, splitting it into 20 equal parts.\n",
      "sending the task #0001\n",
      "sending the task #0002\n",
      "sending the task #0003\n",
      "sending the task #0004\n",
      "sending the task #0005\n",
      "sending the task #0006\n",
      "sending the task #0007\n",
      "sending the task #0008\n",
      "sending the task #0009\n",
      "sending the task #0010\n",
      "sending the task #0011\n",
      "sending the task #0012\n",
      "sending the task #0013\n",
      "sending the task #0014\n",
      "sending the task #0015\n",
      "sending the task #0016\n",
      "sending the task #0017\n",
      "sending the task #0018\n",
      "sending the task #0019\n",
      "sending the task #0020\n"
     ]
    }
   ],
   "source": [
    "export_2D_samples(collection = testing_pts, \n",
    "                  num_of_images = 9, \n",
    "                  num_features = 13, \n",
    "                  dimension = 7, \n",
    "                  file_name_prefix = \"testing_yolo_2016_\", \n",
    "                  folder_name = \"testing_yolo_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEE",
   "language": "python",
   "name": "gee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
